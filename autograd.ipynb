{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff80995-3030-47a5-98c3-0496a54bdcb4",
   "metadata": {},
   "source": [
    "# Gradient : the rate of change of a function with respect to its parameters or variables. In the context of machine learning, the gradient specifically refers to the vector of partial derivatives of a function with respect to each of its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c217e4c-a18e-4189-a934-88c5cd345930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ae4c97-2f76-4dad-bbc2-6a1716544223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3148,  0.8830, -0.2900], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6227d4a-bfd5-4a57-ae97-f00dad7950f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3148, 2.8830, 1.7100], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does a computational graph, like inputs towards neuron and output\n",
    "# for each op we have input and output\n",
    "# using back propogation we can calculate gradient\n",
    "# forwards pass calculates output\n",
    "# because we have gradient activated, pytorch will create a gradient function\n",
    "# y -> grad_fn -> add backward -> backward pass\n",
    "# which will be used in back propogation\n",
    "x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1bd357-6309-4049-a33a-782ee6fc53b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.2592,  3.5319, -1.1600], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2cbfb6-86c9-4342-89cd-223638494fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6359, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8c90c2-f16d-45e4-8b4a-6295529eca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2fd79b-0284-4aa2-a094-e4a94e133ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x*2*2\n",
    "y = y.mean()\n",
    "y.backward() # to compute gradients, we need to reduce the tensor y to a scalar hence the mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348e8bce-0e62-4715-8b56-1d936c220078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6667, 2.6667, 2.6667])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e347be-edc0-46f5-ac02-1c821b181109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if y not scalar, so we did not apply mean()\n",
    "y = x*2*2\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c145f1-4830-41f0-a4fe-5cb6e059f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5eb6de1-2029-41a1-b58b-4e87a42ab777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.backward()\n",
    "y.backward(vector) # vector jakobian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d04d190-bbe4-43e6-967a-bb565499fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.4539, 9.6260, 1.1981])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3808013c-b632-4a96-865e-b041cb54c32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3148,  0.8830, -0.2900])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prevent from tracking gradient if required, example : weight adjustment during training\n",
    "# 3 ways\n",
    "x.requires_grad_(False) # inplace\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d05e8f8d-d334-404d-b69d-d44c649dc253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_no_grad = x.detach()\n",
    "# with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d80f7fac-1db9-4147-bd2c-3e6550060f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True)\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cab51d38-9386-4205-b116-008c39f28600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# so gradient will always sum up\n",
    "# to fix we need to empty gradients\n",
    "weights = torch.ones(4, requires_grad = True)\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414efa6c-5abe-41e6-8fe8-5ba746669667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# optimizer = torch.optim.SGD(weights, lr = 0.01)\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
